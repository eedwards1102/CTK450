<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About the Project - The Environment Reader</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <a href="#main-content" class="skip-link">Skip to main content</a>

    <header>
        <nav aria-label="Main Navigation">
            <ul class="nav-list">
                <li><a href="index.html">Home</a></li>
                <li><a href="about.html" aria-current="page">About the Project</a></li>
                <li><a href="audio-mockups.html">AI Mockup Recordings</a></li>
                <li><a href="ui-experience.html">UI Experience</a></li>
                <li><a href="creator.html">About the Project Creator</a></li>
            </ul>
        </nav>
    </header>

    <main id="main-content">
        <div class="container">
            <h1>About the Project</h1>

            <section>
                <h2>The Inspiration</h2>
                <p>For years, the screen reader has been an assistive technology tool used by those who are blind or visually impaired to use their devices. Screen readers run on phones, computers, tablets, smart watches, and smart home displays. They work via keyboard and touch screen, and when products are made to be accessible, they often work well.</p>
                <p>However, one interesting nuance people may not think of is that all of these devices are 2D. We’re navigating flat, 2D phone and computer interfaces. What happens when we move towards virtual reality? Virtual reality completely changes how we compute.</p>
                <p>We are no longer pointing and clicking, swiping and tapping. We are walking around virtual cities. We are flying through virtual air. We are mingling at virtual campfires. We are playing virtual games as the character, not as the person controlling the character. Immersion is moving beyond the screen.</p>
                <p>Just like in the real world, going places, socializing, and working are things we should all have the ability to do, equal to everyone else. The same goes for VR. Current screen readers, while extremely useful, don't have the level of immersion to give someone who is blind or visually impaired the same ability to explore and navigate that they have in real life.</p>
            </section>

            <section>
                <h2>Why is this so important?</h2>
                <p>With mixed reality on the rise, it is important we make sure these platforms are accessible. Leading virtual reality headsets went years without a screen reader. New headsets have shipped with them, or added this functionality later. But for a long time, those who are blind or visually impaired didn't have a great way to access virtual reality if they couldn't see the screen.</p>
                <p>From headsets like the <a href="https://www.apple.com/apple-vision-pro/">Apple Vision Pro</a>, <a href="https://www.meta.com/quest/?srsltid=AfmBOopPQqFR4NX9NTiCJat4TA5di9vcjOsFGTpIYM6WrCnMhPpbcMfX">Meta Quest</a>, or <a href="https://www.samsung.com/us/xr/galaxy-xr/galaxy-xr/">Samsung Galaxy XR</a>, to new smart glasses initiatives from <a href="google glasses goog…">Google</a> and <a href='#'>Meta</a> that can give us real-world information, the mixed reality space has the possibility to become very prevalent over the next few years.</p>
                <p>It is important to me, as someone who is blind, that we work to make these technologies accessible now so people with disabilities don't get left behind.</p>
            </section>

            <section>
                <h2>The Solution</h2>
                <p>The screen reader needs to evolve into an <strong>Environment Reader</strong>. It isn't enough to just navigate a menu; the software needs to 'read the room,' quite literally. This conceptual software acts as a suite of tools leveraging AI, spatial audio, and haptics to help a user navigate and operate elements in a 3D VR space.</p>
                <p><strong>Artificial Intelligence</strong> serves as the core of this experience. Imagine a natural language AI agent acting as a companion to travel with you through virtual space. With user permission, this AI has read and write control over the environment. A user could simply ask, 'Teleport us to the central square for the concert,' and the AI would guide them there, describing the event and even helping them find others to socialize with.</p>
                <p>To ensure true independence, <strong>Spatial Audio and Haptics</strong> allow users to navigate without constant AI assistance. Audio icons in a grid can act as beacons for positioning, while obstacles could beep as the user approaches them. Haptics provide a tactile layer, potentially allowing users to 'feel' objects as they move and reach around an environment, making the screen reader just as immersive as the environment itself.</p>
            </section>
        </div>
    </main>

</body>
</html>